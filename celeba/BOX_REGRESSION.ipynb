{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc6f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,LocallyConnected2D,BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a85fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 rows and 5 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 10000 # specify 'None' if want to read whole file\n",
    "# list_bbox_celeba.csv has 202599 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df = pd.read_csv('list_bbox_celeba.csv', delimiter=',', nrows = nRowsRead)\n",
    "df.dataframeName = 'list_bbox_celeba.csv'\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5bbad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'x_1', 'y_1', 'width', 'height'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfea59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data_path = \"C:/Users/foreh/Documents/celebaRepo/FacialAttrCNN/celeba/greyscale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f370ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 178\n",
    "height = 218\n",
    "image_size = (width,height)\n",
    "images_data = list()\n",
    "for idx in range(df.shape[0]):\n",
    "    path = \"{}/{}\".format(str(images_data_path),str(df.iloc[idx].image_id))\n",
    "    image = PIL.Image.open(path)\n",
    "    image_array = np.asarray(image)\n",
    "    images_data.append(image_array)\n",
    "images_data = np.array(images_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9b5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Training Set: 7000\n",
      "Samples in Validation Data: 1500\n",
      "Samples in Test Data: 1500\n"
     ]
    }
   ],
   "source": [
    "images = images_data # list of array of images\n",
    "labels = df[[\"image_id\", \"x_1\", \"y_1\", \"width\", \"height\"]]  # dataframe of image features\n",
    "train_images,test_images,train_labels,test_labels = train_test_split(images,labels,test_size=0.3,random_state=(6))\n",
    "y_test=test_labels.drop([\"image_id\"],axis=1)\n",
    "y_train=train_labels.drop([\"image_id\"],axis=1)\n",
    "X_test=test_images\n",
    "X_train=train_images\n",
    "#X_train = tf.expand_dims(X_train, axis=-1)\n",
    "print(\"Samples Training Set:\",len(X_train))\n",
    "X_test, X_val, y_test, y_val=train_test_split(X_test, y_test,test_size=0.5,random_state=(5))\n",
    "print(\"Samples in Validation Data:\",len(X_val))\n",
    "print(\"Samples in Test Data:\",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d2b77f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 72, 59, 24)        240       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 35, 57, 8)         1736      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 17, 28, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 17, 28, 8)         0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 17, 28, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 15, 26, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 13, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 7, 13, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 5, 11, 8)          1160      \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 3, 9, 16)          1168      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 1, 4, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 44)                2860      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                1440      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,000\n",
      "Trainable params: 9,952\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.Input(shape=(image_size[1],image_size[0], 1)))\n",
    "model.add(Conv2D(24, (3,3), strides=(3,3),padding=\"valid\"))\n",
    "model.add(Conv2D(8, (3,3), strides=(2,1)))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(8, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(44))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(4, activation=\"linear\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ddbddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(optimizer = opt,loss=\"huber_loss\",metrics = ['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d84195f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 91.1334 - acc: 0.7514 - mse: 29114.8281 - val_loss: 82.0467 - val_acc: 0.8107 - val_mse: 23523.3301\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 77.9082 - acc: 0.8149 - mse: 23969.8613 - val_loss: 75.8487 - val_acc: 0.8107 - val_mse: 21200.5312\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 73.4943 - acc: 0.8149 - mse: 22026.9160 - val_loss: 67.8702 - val_acc: 0.8107 - val_mse: 16039.3281\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 71.3093 - acc: 0.8149 - mse: 21370.4512 - val_loss: 69.7414 - val_acc: 0.8107 - val_mse: 18850.3848\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 70.3898 - acc: 0.8149 - mse: 20922.8613 - val_loss: 67.6960 - val_acc: 0.8107 - val_mse: 14927.2744\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 69.4683 - acc: 0.8149 - mse: 20601.5938 - val_loss: 65.9458 - val_acc: 0.8107 - val_mse: 16536.7871\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 68.9549 - acc: 0.8149 - mse: 20558.2109 - val_loss: 67.6700 - val_acc: 0.8093 - val_mse: 17600.8418\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 68.7138 - acc: 0.8143 - mse: 20571.9570 - val_loss: 68.8801 - val_acc: 0.8107 - val_mse: 14972.8643\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 67.5639 - acc: 0.8146 - mse: 20325.0859 - val_loss: 65.5619 - val_acc: 0.8053 - val_mse: 14553.9004\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 67.7206 - acc: 0.8136 - mse: 20284.5332 - val_loss: 65.0839 - val_acc: 0.8093 - val_mse: 15436.9814\n"
     ]
    }
   ],
   "source": [
    "training_process = model.fit(X_train,y_train,epochs = 10,validation_data = (X_val,y_val),batch_size=8,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc989eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
